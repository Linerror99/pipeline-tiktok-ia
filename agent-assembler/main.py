import functions_framework
from google.cloud import storage, firestore
import subprocess
import tempfile
from pathlib import Path
import whisper
import os
from datetime import datetime

storage_client = storage.Client()
firestore_client = firestore.Client()

# Configuration V2
BUCKET_NAME_V2 = os.environ.get("BUCKET_NAME_V2", "tiktok-pipeline-v2-artifacts")

# Variable globale pour le mod√®le Whisper (charg√© une seule fois)
WHISPER_MODEL = None

def get_whisper_model():
    """Charge le mod√®le Whisper (une seule fois, puis en cache)"""
    global WHISPER_MODEL
    if WHISPER_MODEL is None:
        print("üì¶ Chargement du mod√®le Whisper (base)...")
        WHISPER_MODEL = whisper.load_model("base")
        print("  ‚úì Mod√®le charg√©")
    return WHISPER_MODEL

def generate_whisper_subtitles_from_video(video_path, output_ass_path):
    """
    G√©n√®re des sous-titres Whisper DIRECTEMENT depuis la vid√©o
    (pas besoin d'extraction audio s√©par√©e)
    """
    print("üéôÔ∏è Transcription Whisper depuis vid√©o...")
    
    try:
        model = get_whisper_model()
        
        # Whisper peut transcrir directement depuis vid√©o !
        result = model.transcribe(
            video_path,  # Accepte vid√©o OU audio
            language="fr",
            word_timestamps=True,
            verbose=False
        )
        
        print(f"  ‚úì Transcription termin√©e")
        
        # === En-t√™te ASS optimis√© TikTok ===
        ass_header = """[Script Info]
Title: TikTok Whisper Subtitles
ScriptType: v4.00+
WrapStyle: 0
PlayResX: 1080
PlayResY: 1920
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial Black,90,&H00FFFFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,6,2,2,10,10,80,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

        ass_events = []
        
        # Extraire tous les mots
        all_words = []
        for segment in result["segments"]:
            if "words" in segment:
                for word_data in segment["words"]:
                    all_words.append({
                        "word": word_data["word"].strip(),
                        "start": word_data["start"],
                        "end": word_data["end"]
                    })
        
        print(f"  ‚úì {len(all_words)} mots extraits")
        
        if not all_words:
            print("‚ö†Ô∏è Aucun mot d√©tect√©")
            return False
        
        # Grouper par 2 mots
        segment_size = 2
        
        for i in range(0, len(all_words), segment_size):
            segment = all_words[i:i+segment_size]
            
            if not segment:
                continue
            
            start_time = max(0, segment[0]['start'] - 0.05)
            end_time = max(start_time + 0.1, segment[-1]['end'] - 0.05)
            
            text = " ".join([w['word'].upper() for w in segment])
            
            start_ass = format_ass_time(start_time)
            end_ass = format_ass_time(end_time)
            
            ass_events.append(f"Dialogue: 0,{start_ass},{end_ass},Default,,0,0,0,,{text}")
        
        # √âcrire fichier ASS
        with open(output_ass_path, 'w', encoding='utf-8') as f:
            f.write(ass_header)
            f.write("\n".join(ass_events))
        
        print(f"  ‚úì Fichier ASS cr√©√©: {len(ass_events)} sous-titres")
        return True
        
    except Exception as e:
        print(f"  ‚ùå Erreur Whisper: {e}")
        import traceback
        traceback.print_exc()
        return False


def format_ass_time(seconds):
    """Convertit secondes en format ASS (0:00:00.00)"""
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    cs = int((seconds % 1) * 100)
    return f"{h}:{m:02d}:{s:02d}.{cs:02d}"

def generate_whisper_subtitles_from_video(video_path, output_ass_path):
    """
    G√©n√®re des sous-titres Whisper DIRECTEMENT depuis la vid√©o
    (pas besoin d'extraction audio s√©par√©e)
    """
    print("üéôÔ∏è Transcription Whisper depuis vid√©o...")
    
    try:
        model = get_whisper_model()
        
        # Whisper peut transcrire directement depuis vid√©o !
        result = model.transcribe(
            video_path,  # Accepte vid√©o OU audio
            language="fr",
            word_timestamps=True,
            verbose=False
        )
        
        print(f"  ‚úì Transcription termin√©e")
        
        # === En-t√™te ASS optimis√© TikTok ===
        ass_header = """[Script Info]
Title: TikTok Whisper Subtitles
ScriptType: v4.00+
WrapStyle: 0
PlayResX: 1080
PlayResY: 1920
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial Black,90,&H00FFFFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,6,2,2,10,10,80,1
Style: Highlight,Arial Black,95,&H0000FFFF,&H0000FFFF,&H00000000,&H80000000,-1,0,0,0,105,105,0,0,1,7,3,2,10,10,80,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

        ass_events = []
        
        # Extraire tous les mots
        all_words = []
        for segment in result["segments"]:
            if "words" in segment:
                for word_data in segment["words"]:
                    all_words.append({
                        "word": word_data["word"].strip(),
                        "start": word_data["start"],
                        "end": word_data["end"]
                    })
        
        print(f"  ‚úì {len(all_words)} mots extraits")
        
        if not all_words:
            print("‚ö†Ô∏è Aucun mot d√©tect√©")
            return False
        
        # Grouper par 2 mots pour lisibilit√©
        segment_size = 2
        
        for i in range(0, len(all_words), segment_size):
            segment = all_words[i:i+segment_size]
            
            if not segment:
                continue
            
            start_time = segment[0]['start']
            end_time = segment[-1]['end']
            
            # Petite avance de 50ms pour anticipation
            start_time = max(0, start_time - 0.05)
            end_time = max(start_time + 0.1, end_time - 0.05)
            
            # Texte en MAJUSCULES
            text = " ".join([w['word'].upper() for w in segment])
            
            # Point de highlight (35% du temps)
            highlight_point = start_time + (end_time - start_time) * 0.35
            
            start_ass = format_timestamp_ass(start_time)
            highlight_ass = format_timestamp_ass(highlight_point)
            end_ass = format_timestamp_ass(end_time)
            
            # Blanc ‚Üí Jaune
            ass_events.append(f"Dialogue: 0,{start_ass},{highlight_ass},Default,,0,0,0,,{text}")
            ass_events.append(f"Dialogue: 0,{highlight_ass},{end_ass},Highlight,,0,0,0,,{text}")
        
        # √âcrire le fichier ASS
        with open(output_ass_path, 'w', encoding='utf-8') as f:
            f.write(ass_header)
            f.write("\n".join(ass_events))
        
        print(f"  ‚úì {len(ass_events)} √©v√©nements ASS g√©n√©r√©s avec Whisper")
        return True
        
    except Exception as e:
        print(f"  ‚ùå Erreur Whisper: {e}")
        import traceback
        traceback.print_exc()
        return False

def generate_whisper_subtitles(audio_path, output_ass_path):
    """
    DEPRECATED - Utiliser generate_whisper_subtitles_from_video √† la place
    G√©n√®re des sous-titres avec Whisper - Synchronisation PARFAITE
    """
    print("üéôÔ∏è Transcription avec Whisper (open-source)...")
    
    model = get_whisper_model()
    
    # Transcrire avec timestamps par mot
    result = model.transcribe(
        audio_path,
        language="fr",
        word_timestamps=True,  # CRUCIAL
        verbose=False
    )
    
    print(f"  ‚úì Transcription termin√©e")
    
    # === En-t√™te ASS optimis√© TikTok ===
    ass_header = """[Script Info]
Title: TikTok Whisper Subtitles
ScriptType: v4.00+
WrapStyle: 0
PlayResX: 1080
PlayResY: 1920
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial Black,90,&H00FFFFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,6,2,2,10,10,80,1
Style: Highlight,Arial Black,95,&H0000FFFF,&H0000FFFF,&H00000000,&H80000000,-1,0,0,0,105,105,0,0,1,7,3,2,10,10,80,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

    ass_events = []
    
    # Extraire tous les mots avec leurs timestamps
    all_words = []
    for segment in result["segments"]:
        if "words" in segment:
            for word_data in segment["words"]:
                all_words.append({
                    "word": word_data["word"].strip(),
                    "start": word_data["start"],
                    "end": word_data["end"]
                })
    
    print(f"  ‚úì {len(all_words)} mots extraits")
    
    if not all_words:
        print("‚ö†Ô∏è Aucun mot d√©tect√©")
        return False
    
    # Grouper par 2 mots pour lisibilit√©
    segment_size = 2
    
    for i in range(0, len(all_words), segment_size):
        segment = all_words[i:i+segment_size]
        
        if not segment:
            continue
        
        start_time = segment[0]['start']
        end_time = segment[-1]['end']
        
        # Petite avance de 50ms pour anticipation
        start_time = max(0, start_time - 0.05)
        end_time = max(start_time + 0.1, end_time - 0.05)
        
        # Texte en MAJUSCULES
        text = " ".join([w['word'].upper() for w in segment])
        
        # Point de highlight (35% du temps)
        highlight_point = start_time + (end_time - start_time) * 0.35
        
        start_ass = format_timestamp_ass(start_time)
        highlight_ass = format_timestamp_ass(highlight_point)
        end_ass = format_timestamp_ass(end_time)
        
        # Blanc ‚Üí Jaune
        ass_events.append(f"Dialogue: 0,{start_ass},{highlight_ass},Default,,0,0,0,,{text}")
        ass_events.append(f"Dialogue: 0,{highlight_ass},{end_ass},Highlight,,0,0,0,,{text}")
    
    # √âcrire le fichier ASS
    with open(output_ass_path, 'w', encoding='utf-8') as f:
        f.write(ass_header)
        f.write("\n".join(ass_events))
    
    print(f"  ‚úì {len(ass_events)} √©v√©nements ASS g√©n√©r√©s avec Whisper")
    return True

def format_timestamp_ass(seconds):
    """Convertit des secondes en format ASS (H:MM:SS.cc)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    centisecs = int((seconds % 1) * 100)
    return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"

@functions_framework.cloud_event
def assemble_video(cloudevent):
    """
    Cloud Function d√©clench√©e par upload de block_N.mp4 (dernier bloc)
    Ajoute sous-titres Whisper sur vid√©o finale
    
    CloudEvent data:
    {
        "bucket": "tiktok-pipeline-v2-artifacts",
        "name": "{video_id}/block_N.mp4"
    }
    """
    try:
        data = cloudevent.data
        bucket_name = data["bucket"]
        file_name = data["name"]
        
        print(f"üì° D√©clencheur re√ßu pour le fichier : {file_name}")
        
        # V√©rifier que c'est bien un block_*.mp4 ET que c'est un d√©clenchement pour assembly
        # (monitor-veo31 upload block_N.mp4 avec metadata assembly=true)
        if not "/block_" in file_name or not file_name.endswith(".mp4"):
            print(f"‚ö†Ô∏è Fichier non-block {file_name}. Traitement ignor√©.")
            return "OK"
        
        # Extraire video_id du path: {video_id}/block_N.mp4
        video_id = file_name.split("/")[0]
        
        print(f"üéûÔ∏è Assemblage final pour video_id: {video_id}")
        
    except Exception as e:
        print(f"‚ùå Erreur parsing CloudEvent: {e}")
        return "ERROR"
    
    print("=" * 70)
    print(f"üé¨ Assemblage V2 pour: {video_id}")
    print("=" * 70)
    
    try:
        # R√©cup√©rer infos depuis Firestore
        op_doc = firestore_client.collection('v2_veo_operations').document(video_id).get()
        
        if not op_doc.exists:
            print(f"‚ùå v2_veo_operations/{video_id} non trouv√©")
            return "ERROR"
        
        op_data = op_doc.to_dict()
        total_blocks = op_data['total_blocks']
        
        print(f"üìä Total blocs: {total_blocks}")
        
        # R√©cup√©rer LA vid√©o finale (block_N.mp4 contient TOUS les blocs assembl√©s)
        bucket = storage_client.bucket(BUCKET_NAME_V2)
        final_block_blob = bucket.blob(f'{video_id}/block_{total_blocks}.mp4')
        
        if not final_block_blob.exists():
            return {"error": f"Vid√©o finale block_{total_blocks}.mp4 non trouv√©e"}, 404
        
        print(f"‚úÖ Vid√©o finale trouv√©e: block_{total_blocks}.mp4")
        
        # Cr√©er r√©pertoire temp
        with tempfile.TemporaryDirectory() as tmpdir:
            tmpdir_path = Path(tmpdir)
            
            # T√©l√©charger vid√©o finale
            final_video = tmpdir_path / "final_video.mp4"
            final_block_blob.download_to_filename(str(final_video))
            print(f"üì• Vid√©o t√©l√©charg√©e: {final_video}")
            
            # 1. Extraire audio de la vid√©o
            audio_path = tmpdir_path / "audio.wav"
            print("\nüéµ Extraction audio...")
            subprocess.run([
                'ffmpeg', '-i', str(final_video),
                '-vn', '-acodec', 'pcm_s16le',
                '-ar', '16000', '-ac', '1',
                str(audio_path)
            ], check=True, capture_output=True)
            print("  ‚úì Audio extrait")
            
            # 2. Whisper sur audio
            print("\nüéôÔ∏è Transcription Whisper...")
            ass_path = tmpdir_path / "subtitles.ass"
            success = generate_whisper_subtitles(str(audio_path), str(ass_path))
            
            if not success:
                return {"error": "√âchec g√©n√©ration sous-titres Whisper"}, 500
            
            # 3. Ajouter sous-titres √† la vid√©o
            final_with_subs = tmpdir_path / "final_with_subs.mp4"
            print("\nüìù Ajout sous-titres...")
            subprocess.run([
                'ffmpeg', '-i', str(final_video),
                '-vf', f"ass={ass_path}",
                '-c:a', 'copy',
                str(final_with_subs)
            ], check=True, capture_output=True)
            print("  ‚úì Sous-titres ajout√©s")
            
            # 4. Upload vid√©o finale
            final_blob = bucket.blob(f'{video_id}/final.mp4')
            final_blob.upload_from_filename(str(final_output))
            public_url = f"gs://{BUCKET_NAME_V2}/{video_id}/final.mp4"
            
            print(f"\n‚úÖ Vid√©o finale upload√©e: {public_url}")
            
            # 5. Update Firestore
            firestore_client.collection('v2_veo_operations').document(video_id).update({
                'status': 'completed',
                'final_url': public_url,
                'updated_at': firestore.SERVER_TIMESTAMP
            })
            
            firestore_client.collection('v2_video_status').document(video_id).update({
                'status': 'completed',
                'final_url': public_url,
                'completed_at': firestore.SERVER_TIMESTAMP
            })
            
            print("\n" + "=" * 70)
            print(f"üéâ Assemblage V2 termin√© !")
            print("=" * 70)
            
            return {
                "status": "success",
                "video_id": video_id,
                "final_url": public_url,
                "total_blocks": total_blocks
            }, 200
            
    except subprocess.CalledProcessError as e:
        error_msg = f"Erreur FFmpeg: {e.stderr.decode() if e.stderr else str(e)}"
        print(f"‚ùå {error_msg}")
        mark_as_failed(video_id, error_msg)
        return {"error": error_msg}, 500
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå Erreur: {error_msg}")
        import traceback
        traceback.print_exc()
        mark_as_failed(video_id, error_msg)
        return {"error": error_msg}, 500


def mark_as_failed(video_id, error_message):
    """Marque la vid√©o comme √©chou√©e"""
    try:
        firestore_client.collection('v2_veo_operations').document(video_id).update({
            'status': 'failed',
            'error_message': error_message,
            'updated_at': firestore.SERVER_TIMESTAMP
        })
        
        firestore_client.collection('v2_video_status').document(video_id).update({
            'status': 'error',
            'error_message': f'Assemblage √©chou√©: {error_message}',
            'updated_at': firestore.SERVER_TIMESTAMP
        })
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur update Firestore: {e}")
    clips = video_status['clips']
    
    print(f"üìä Status vid√©o: {video_status['status']}")
    print(f"üìä Clips attendus: {video_status['total_clips']}")
    print(f"ÔøΩ Clips compl√©t√©s: {video_status['completed_clips']}")

    bucket = storage_client.bucket(bucket_name)
    prefix = f"video_clips/{video_base_name}/"
    blobs = list(bucket.list_blobs(prefix=prefix))
    
    video_clips = sorted([b.name for b in blobs if b.name.endswith(".mp4")])
    print(f"üìä Clips trouv√©s dans GCS : {len(video_clips)}")

    # Lire le script
    script_file_name = f"script_{video_base_name}.txt"
    try:
        script_blob = bucket.blob(script_file_name)
        if not script_blob.exists():
            print(f"‚ùå Script non trouv√©")
            return {"error": "Script not found"}, 404
        script_content = script_blob.download_as_text(encoding="utf-8")
    except Exception as e:
        print(f"‚ùå Erreur script : {e}")
        return {"error": f"Script error: {str(e)}"}, 500

    expected_clips = script_content.upper().count("VISUEL")
    print(f"üéØ Clips attendus (depuis script) : {expected_clips}")

    # V√©rifier si d√©j√† assembl√©
    final_video_name = f"final_{video_base_name}.mp4"
    final_blob = bucket.blob(final_video_name)
    if final_blob.exists():
        print(f"‚úÖ Vid√©o finale existe d√©j√†")
        return {"status": "already_exists", "video_id": video_base_name}, 200

    print("üéâ Lancement de l'assemblage avec Whisper...")

    with tempfile.TemporaryDirectory() as tmpdir:
        tmpdir_path = Path(tmpdir)
        
        print("üì• T√©l√©chargement des clips...")
        clip_files = []
        for i, clip_name in enumerate(video_clips):
            local_clip_path = tmpdir_path / f"clip_{i:03d}.mp4"
            bucket.blob(clip_name).download_to_filename(str(local_clip_path))
            clip_files.append(local_clip_path)
            print(f"  ‚úì Clip {i+1}/{len(video_clips)}")

        # T√©l√©charger l'audio
        audio_file_name = f"audio_{video_base_name}.mp3"
        audio_blob = bucket.blob(audio_file_name)
        if not audio_blob.exists():
            print(f"‚ùå Audio non trouv√©")
            return "Error"
        
        local_audio_path = tmpdir_path / "narration.mp3"
        audio_blob.download_to_filename(str(local_audio_path))
        print(f"üéµ Audio t√©l√©charg√©")

        # G√©n√©rer les sous-titres avec Whisper
        ass_path = tmpdir_path / "subtitles.ass"
        subtitles_generated = generate_whisper_subtitles(str(local_audio_path), str(ass_path))

        # Fichier de concat√©nation
        concat_file = tmpdir_path / "concat_list.txt"
        with open(concat_file, 'w') as f:
            for clip_file in clip_files:
                f.write(f"file '{clip_file.absolute()}'\n")

        print("üé¨ √âtape 1/3 : Concat√©nation...")
        concat_video = tmpdir_path / "concat_video.mp4"
        try:
            subprocess.run([
                'ffmpeg', '-f', 'concat', '-safe', '0', '-i', str(concat_file),
                '-c', 'copy', '-y', str(concat_video)
            ], capture_output=True, check=True, text=True)
            print("  ‚úì Concat√©n√©")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Erreur concat : {e.stderr}")
            return "Error"

        print("üé¨ √âtape 2/3 : Audio...")
        video_with_audio = tmpdir_path / "video_with_audio.mp4"
        try:
            subprocess.run([
                'ffmpeg', '-i', str(concat_video), '-i', str(local_audio_path),
                '-c:v', 'copy', '-c:a', 'aac', '-b:a', '192k',
                '-map', '0:v:0', '-map', '1:a:0', '-shortest', '-y', str(video_with_audio)
            ], capture_output=True, check=True, text=True)
            print("  ‚úì Audio")
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Erreur audio : {e.stderr}")
            return "Error"

        # Sous-titres
        if subtitles_generated and ass_path.exists():
            print("üé¨ √âtape 3/3 : Sous-titres Whisper...")
            final_video = tmpdir_path / "final_video.mp4"
            try:
                subprocess.run([
                    'ffmpeg', '-i', str(video_with_audio),
                    '-vf', f"ass={str(ass_path)}",
                    '-c:a', 'copy',
                    '-y', str(final_video)
                ], capture_output=True, check=True, text=True)
                print("  ‚úì Sous-titres Whisper")
            except subprocess.CalledProcessError as e:
                print(f"‚ö†Ô∏è Erreur sous-titres : {e.stderr[-500:]}")
                final_video = video_with_audio
        else:
            print("‚ö†Ô∏è Pas de sous-titres")
            final_video = video_with_audio

        if not final_video.exists() or final_video.stat().st_size == 0:
            print("‚ùå Vid√©o vide")
            return "Error"

        final_size_mb = final_video.stat().st_size / (1024 * 1024)
        print(f"üì§ Upload ({final_size_mb:.2f} MB)...")

        try:
            final_blob.upload_from_filename(str(final_video), content_type="video/mp4")
            final_video_url = f"gs://{bucket_name}/{final_video_name}"
            print(f"‚úÖ SUCC√àS ! {final_video_url}")
            
            # Mettre √† jour Firestore : status = completed
            firestore_client.collection('video_status').document(video_base_name).update({
                'status': 'completed',
                'final_video_url': final_video_url,
                'updated_at': datetime.utcnow()
            })
            print(f"üìù Firestore mis √† jour : status=completed")
            
        except Exception as e:
            print(f"‚ùå Erreur upload : {e}")
            
            # Mettre √† jour Firestore : status = failed
            firestore_client.collection('video_status').document(video_base_name).update({
                'status': 'failed',
                'error': str(e),
                'updated_at': datetime.utcnow()
            })
            
            return {"error": f"Upload error: {str(e)}"}, 500

    print(f"üéâ ASSEMBLAGE WHISPER TERMIN√â !")
    
    return {
        "status": "success",
        "video_id": video_base_name,
        "final_video_url": f"gs://{bucket_name}/{final_video_name}"
    }, 200